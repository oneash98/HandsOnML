{"cells":[{"cell_type":"markdown","metadata":{"id":"Y6llzZxl8_Aq"},"source":["# 16. RNN과 어텐션을 사용한 자연어 처리"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1698826882470,"user":{"displayName":"Hanjae Kim","userId":"02991760026987687501"},"user_tz":-540},"id":"WYhMpBRp8_Au"},"outputs":[],"source":["# 공통 모듈 임포트\n","import numpy as np\n","import os\n","\n","# 깔금한 그래프 출력을 위해\n","%matplotlib inline\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","mpl.rc('axes', labelsize=14)\n","mpl.rc('xtick', labelsize=12)\n","mpl.rc('ytick', labelsize=12)\n","plt.rc('font', family='AppleGothic')\n","plt.rcParams['axes.unicode_minus'] = False"]},{"cell_type":"markdown","metadata":{"id":"u5ZMWqJA8_Aw"},"source":["## 16.1 Char-RNN으로 셰익스피어 문체 생성하기"]},{"cell_type":"markdown","metadata":{"id":"u51YkglP8_Aw"},"source":["### 16.1.1 훈련 데이터셋 만들기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GyjbPFeb8_Aw"},"outputs":[],"source":["import tensorflow as tf\n","\n","import ssl\n","ssl._create_default_https_context = ssl._create_unverified_context\n","\n","shakespeare_url = 'https://homl.info/shakespeare'\n","filepath = tf.keras.utils.get_file('shakespeare.txt', shakespeare_url)\n","with open(filepath) as f:\n","    shakespeare_text = f.read()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xqt72aOo8_Ax","outputId":"2933d6ed-8813-443a-edb9-66e8c95ae0b7"},"outputs":[{"name":"stdout","output_type":"stream","text":["First Citizen:\n","Before we proceed any further, hear me speak.\n","\n","All:\n","Speak, speak.\n"]}],"source":["print(shakespeare_text[:80])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jpktOluz8_Ax","outputId":"8ab2d900-141f-4166-9575-822f3f6bd4d3"},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-11-01 17:02:46.485173: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"]}],"source":["text_vec_layer = tf.keras.layers.TextVectorization(split = 'character', standardize='lower')\n","text_vec_layer.adapt([shakespeare_text])\n","encoded = text_vec_layer([shakespeare_text])[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K3L9ZKyI8_Ay"},"outputs":[],"source":["encoded -= 2\n","n_tokens = text_vec_layer.vocabulary_size() - 2\n","dataset_size = len(encoded)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9u_2TfoG8_Ay"},"outputs":[],"source":["def to_dataset(sequence, length, shuffle = False, seed = None, batch_size = 32):\n","    ds = tf.data.Dataset.from_tensor_slices(sequence)\n","    ds = ds.window(length + 1, shift = 1, drop_remainder = True)\n","    ds = ds.flat_map(lambda window_ds: window_ds.batch(length + 1))\n","    if shuffle:\n","        ds = ds.shuffle(buffer_size = 100_000, seed=seed)\n","    ds = ds.batch(batch_size)\n","    return ds.map(lambda window: (window[:, :-1], window[:, 1:])).prefetch(1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cZ9C2CH48_Az"},"outputs":[],"source":["length = 100\n","tf.random.set_seed(42)\n","train_set = to_dataset(encoded[:1_000_000], length=length, shuffle=True, seed = 42)\n","valid_set = to_dataset(encoded[1_000_000:1_060_000], length=length)\n","test_set = to_dataset(encoded[1_060_000:], length=length)"]},{"cell_type":"markdown","metadata":{"id":"wCFtNwYM8_Az"},"source":["### 16.1.2 Char-RNN 모델 만들고 훈련하기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gt3_gwzb8_Az","outputId":"1c32f59c-3659-43dd-dd10-6d7476f1b474"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/2\n"]},{"name":"stderr","output_type":"stream","text":["2023-11-01 17:02:53.152280: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n","2023-11-01 17:03:01.229903: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n","2023-11-01 17:03:01.654143: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m/Users/oneash/ONEASH/Coding/HandsOnML/codes/16_nlp_with_rnns_and_attention.ipynb Cell 12\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/oneash/ONEASH/Coding/HandsOnML/codes/16_nlp_with_rnns_and_attention.ipynb#X14sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msparse_categorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m, optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnadam\u001b[39m\u001b[39m'\u001b[39m, metrics \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/oneash/ONEASH/Coding/HandsOnML/codes/16_nlp_with_rnns_and_attention.ipynb#X14sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m model_ckpt \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mModelCheckpoint(\u001b[39m'\u001b[39m\u001b[39mmy_shakespeare_model\u001b[39m\u001b[39m'\u001b[39m, monitor \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mval_accuracy\u001b[39m\u001b[39m'\u001b[39m, save_best_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/oneash/ONEASH/Coding/HandsOnML/codes/16_nlp_with_rnns_and_attention.ipynb#X14sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(train_set, validation_data\u001b[39m=\u001b[39;49m valid_set, epochs\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, callbacks\u001b[39m=\u001b[39;49m[model_ckpt])\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1743\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:890\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    886\u001b[0m     \u001b[39mpass\u001b[39;00m  \u001b[39m# Fall through to cond-based initialization.\u001b[39;00m\n\u001b[1;32m    887\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    888\u001b[0m     \u001b[39m# Lifting succeeded, so variables are initialized and we can run the\u001b[39;00m\n\u001b[1;32m    889\u001b[0m     \u001b[39m# no_variable_creation function.\u001b[39;00m\n\u001b[0;32m--> 890\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    891\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    892\u001b[0m   _, _, filtered_flat_args \u001b[39m=\u001b[39m (\n\u001b[1;32m    893\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn\u001b[39m.\u001b[39m_function_spec  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    894\u001b[0m       \u001b[39m.\u001b[39mcanonicalize_function_inputs(\n\u001b[1;32m    895\u001b[0m           args, kwds))\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    149\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function(\u001b[39m*\u001b[39;49margs))\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    197\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    198\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[1;32m    199\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[1;32m    200\u001b[0m     )\n\u001b[1;32m    201\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\u001b[39mself\u001b[39m, \u001b[39mlist\u001b[39m(args))\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m   1458\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1459\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[1;32m   1460\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[1;32m   1461\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m   1462\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1463\u001b[0m   )\n\u001b[1;32m   1464\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["model = tf.keras.Sequential([\n","    tf.keras.layers.Embedding(input_dim = n_tokens, output_dim=16),\n","    tf.keras.layers.GRU(128, return_sequences=True),\n","    tf.keras.layers.Dense(n_tokens, activation = 'softmax')\n","])\n","\n","model.compile(loss='sparse_categorical_crossentropy', optimizer='nadam', metrics = ['accuracy'])\n","model_ckpt = tf.keras.callbacks.ModelCheckpoint('my_shakespeare_model', monitor = 'val_accuracy', save_best_only=True)\n","history = model.fit(train_set, validation_data= valid_set, epochs=2, callbacks=[model_ckpt])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6b1-2z9j8_A0"},"outputs":[],"source":["shakespeare_model = tf.keras.Sequential([\n","    text_vec_layer,\n","    tf.keras.layers.Lambda(lambda X: X - 2),\n","    model\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GunkSJmL8_A0","outputId":"d1f5d1da-817f-414d-ae9c-acc6d27b5877"},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-10-30 02:07:06.127252: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n","2023-10-30 02:07:06.240412: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"]},{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 1s 645ms/step\n"]},{"data":{"text/plain":["'e'"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["y_proba = shakespeare_model.predict(['To be or not to b'])[0, -1]\n","y_pred = tf.argmax(y_proba)\n","text_vec_layer.get_vocabulary()[y_pred + 2]"]},{"cell_type":"markdown","metadata":{"id":"cioQF6dw8_A0"},"source":["### 16.1.3 가짜 셰익스피어 텍스트 생성하기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xxsgt5RT8_A0"},"outputs":[],"source":["def next_char(text, temperature = 1):\n","    y_proba = shakespeare_model.predict([text])[0, -1:]\n","    rescaled_logit = tf.math.log(y_proba) / temperature\n","    char_id = tf.random.categorical(rescaled_logit, num_samples=1)[0, 0]\n","    return text_vec_layer.get_vocabulary()[char_id + 2]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kJsE-OF68_A0"},"outputs":[],"source":["def extend_text(text, n_chars = 50, temperature = 1):\n","    for _ in range(n_chars):\n","        text += next_char(text, temperature)\n","\n","    return text"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o9pL33Kk8_A0"},"outputs":[],"source":["tf.random.set_seed(42)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IOLVQMfT8_A0","outputId":"f404eb20-2da3-4eaf-a4c6-8cb6e97bc959"},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 149ms/step\n"]},{"name":"stderr","output_type":"stream","text":["2023-10-30 02:07:07.032339: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n","2023-10-30 02:07:07.102589: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"]},{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 39ms/step\n","1/1 [==============================] - 0s 39ms/step\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 39ms/step\n","1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 35ms/step\n","1/1 [==============================] - 0s 38ms/step\n","1/1 [==============================] - 0s 38ms/step\n","1/1 [==============================] - 0s 39ms/step\n","1/1 [==============================] - 0s 38ms/step\n","1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 35ms/step\n","1/1 [==============================] - 0s 35ms/step\n","1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 38ms/step\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 101ms/step\n","1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 38ms/step\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 38ms/step\n","1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 35ms/step\n","1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 38ms/step\n","1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 38ms/step\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 38ms/step\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 38ms/step\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 38ms/step\n"]},{"data":{"text/plain":["'To be or not to be the the the the the the the the the the the the t'"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["extend_text('To be or not to be', temperature=0.01)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ButL-X0B8_A0","outputId":"d8d2824d-2951-431e-c251-bbecca3e3b09"},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 48ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 38ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 30ms/step\n"]},{"data":{"text/plain":["'To be or not to bes\\n\\nibosie:\\nberp, grecled,\\na mance grrore me wilich'"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["extend_text('To be or not to be', temperature=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rrSx7U3g8_A1","outputId":"d16d8a57-3fc4-43d4-d5d0-b042b105f4ff"},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 47ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 32ms/step\n"]},{"data":{"text/plain":["\"To be or not to beg ,mt'&o3f:ady-$\\nws-nse?pws&ertj-vberdjw!c-yjewznq\""]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["extend_text('To be or not to be', temperature=100)"]},{"cell_type":"markdown","metadata":{"id":"66-IKYw_8_A1"},"source":["### 16.1.4 상태가 있는 RNN"]},{"cell_type":"markdown","metadata":{"id":"5fhDgR9-8_A1"},"source":["## 16.2 감성 분석"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XWK_hmEd8_A1"},"outputs":[],"source":["import tensorflow_datasets as tfds\n","\n","raw_train_set, raw_valid_set, raw_test_set = tfds.load(\n","    name = 'imdb_reviews',\n","    split = ['train[:90%]', 'train[90%:]', 'test'],\n","    as_supervised=True\n",")\n","\n","tf.random.set_seed(42)\n","train_set = raw_train_set.shuffle(5000, seed=42).batch(32).prefetch(1)\n","valid_set = raw_valid_set.batch(32).prefetch(1)\n","test_set = raw_test_set.batch(32).prefetch(1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qazZ0H2F8_A1","outputId":"9eaa71ee-53cf-4c1b-c8b7-72faf3e67aaf"},"outputs":[{"name":"stdout","output_type":"stream","text":["This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\n","레이블: 0\n","I have been known to fall asleep during films, but this is usually due to a combination of things including, really tired, being warm and comfortable on the sette and having just eaten a lot. However on this occasion I fell asleep because the film was rubbish. The plot development was constant. Constantly slow and boring. Things seemed to happen, but with no explanation of what was causing them or why. I admit, I may have missed part of the film, but i watched the majority of it and everything just seemed to happen of its own accord without any real concern for anything else. I cant recommend this film at all.\n","레이블: 0\n","Mann photographs the Alberta Rocky Mountains in a superb fashion, and Jimmy Stewart and Walter Brennan give enjoyable performances as they always seem to do. <br /><br />But come on Hollywood - a Mountie telling the people of Dawson City, Yukon to elect themselves a marshal (yes a marshal!) and to enforce the law themselves, then gunfighters battling it out on the streets for control of the town? <br /><br />Nothing even remotely resembling that happened on the Canadian side of the border during the Klondike gold rush. Mr. Mann and company appear to have mistaken Dawson City for Deadwood, the Canadian North for the American Wild West.<br /><br />Canadian viewers be prepared for a Reefer Madness type of enjoyable howl with this ludicrous plot, or, to shake your head in disgust.\n","레이블: 0\n","This is the kind of film for a snowy Sunday afternoon when the rest of the world can go ahead with its own business as you descend into a big arm-chair and mellow for a couple of hours. Wonderful performances from Cher and Nicolas Cage (as always) gently row the plot along. There are no rapids to cross, no dangerous waters, just a warm and witty paddle through New York life at its best. A family film in every sense and one that deserves the praise it received.\n","레이블: 1\n"]},{"name":"stderr","output_type":"stream","text":["2023-10-30 14:02:39.954376: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"]}],"source":["for review, label in raw_train_set.take(4):\n","    print(review.numpy().decode('utf-8'))\n","    print('레이블:', label.numpy())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z4CmBASy8_A1","outputId":"81ccc650-dca3-4326-c401-e070755ca31b"},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-10-30 14:02:41.278466: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"]}],"source":["vocab_size = 1000\n","text_vec_layer = tf.keras.layers.TextVectorization(max_tokens=vocab_size)\n","text_vec_layer.adapt(train_set.map(lambda reviews, labels: reviews))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AS7sw3ae8_A1","outputId":"1833a95e-ac15-4ec4-b266-e32f260ed452"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/2\n"]},{"name":"stderr","output_type":"stream","text":["2023-10-30 14:02:43.788497: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n","2023-10-30 14:02:44.036392: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n","2023-10-30 14:02:44.205149: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"]},{"name":"stdout","output_type":"stream","text":["704/704 [==============================] - ETA: 0s - loss: 0.6940 - accuracy: 0.4978"]},{"name":"stderr","output_type":"stream","text":["2023-10-30 14:04:30.184217: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n","2023-10-30 14:04:30.317455: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"]},{"name":"stdout","output_type":"stream","text":["704/704 [==============================] - 113s 159ms/step - loss: 0.6940 - accuracy: 0.4978 - val_loss: 0.6929 - val_accuracy: 0.5012\n","Epoch 2/2\n","704/704 [==============================] - 141s 200ms/step - loss: 0.6928 - accuracy: 0.5053 - val_loss: 0.6952 - val_accuracy: 0.5012\n"]}],"source":["embed_size = 128\n","tf.random.set_seed(42)\n","model = tf.keras.Sequential([\n","    text_vec_layer,\n","    tf.keras.layers.Embedding(vocab_size, embed_size),\n","    tf.keras.layers.GRU(128),\n","    tf.keras.layers.Dense(1, activation='sigmoid')\n","])\n","model.compile(loss='binary_crossentropy', optimizer='nadam', metrics=['accuracy'])\n","history = model.fit(train_set, validation_data=valid_set, epochs=2)"]},{"cell_type":"markdown","metadata":{"id":"X5LvL0zu8_A1"},"source":["### 16.2.1 마스킹"]},{"cell_type":"markdown","metadata":{"id":"Pr6IS8md8_A1"},"source":["### 16.2.2 사전 훈련된 임베딩과 언어 모델 재사용하기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TzLrJeBW8_A2","outputId":"9fed7ebe-3db9-459f-baa7-d9b6f71ea465"},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-10-30 14:08:26.220974: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["2023-10-30 14:08:34.643137: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m/Users/oneash/ONEASH/Coding/HandsOnML/codes/16_nlp_with_rnns_and_attention.ipynb Cell 30\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/oneash/ONEASH/Coding/HandsOnML/codes/16_nlp_with_rnns_and_attention.ipynb#X41sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mSequential([\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/oneash/ONEASH/Coding/HandsOnML/codes/16_nlp_with_rnns_and_attention.ipynb#X41sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     hub\u001b[39m.\u001b[39mKerasLayer(\u001b[39m'\u001b[39m\u001b[39mhttps://tfhub.dev/google/universal-sentence-encoder/4\u001b[39m\u001b[39m'\u001b[39m, trainable\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, dtype\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mstring, input_shape\u001b[39m=\u001b[39m[]),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/oneash/ONEASH/Coding/HandsOnML/codes/16_nlp_with_rnns_and_attention.ipynb#X41sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(\u001b[39m64\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/oneash/ONEASH/Coding/HandsOnML/codes/16_nlp_with_rnns_and_attention.ipynb#X41sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(\u001b[39m1\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msigmoid\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/oneash/ONEASH/Coding/HandsOnML/codes/16_nlp_with_rnns_and_attention.ipynb#X41sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m ])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/oneash/ONEASH/Coding/HandsOnML/codes/16_nlp_with_rnns_and_attention.ipynb#X41sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary_crossentropy\u001b[39m\u001b[39m'\u001b[39m, optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnadam\u001b[39m\u001b[39m'\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/oneash/ONEASH/Coding/HandsOnML/codes/16_nlp_with_rnns_and_attention.ipynb#X41sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(train_set, validation_data\u001b[39m=\u001b[39;49mvalid_set, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1743\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:890\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    886\u001b[0m     \u001b[39mpass\u001b[39;00m  \u001b[39m# Fall through to cond-based initialization.\u001b[39;00m\n\u001b[1;32m    887\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    888\u001b[0m     \u001b[39m# Lifting succeeded, so variables are initialized and we can run the\u001b[39;00m\n\u001b[1;32m    889\u001b[0m     \u001b[39m# no_variable_creation function.\u001b[39;00m\n\u001b[0;32m--> 890\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    891\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    892\u001b[0m   _, _, filtered_flat_args \u001b[39m=\u001b[39m (\n\u001b[1;32m    893\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn\u001b[39m.\u001b[39m_function_spec  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    894\u001b[0m       \u001b[39m.\u001b[39mcanonicalize_function_inputs(\n\u001b[1;32m    895\u001b[0m           args, kwds))\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    149\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function(\u001b[39m*\u001b[39;49margs))\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    197\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    198\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[1;32m    199\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[1;32m    200\u001b[0m     )\n\u001b[1;32m    201\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\u001b[39mself\u001b[39m, \u001b[39mlist\u001b[39m(args))\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m   1458\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1459\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[1;32m   1460\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[1;32m   1461\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m   1462\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1463\u001b[0m   )\n\u001b[1;32m   1464\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import os\n","import tensorflow_hub as hub\n","\n","\n","os.environ['TFHUB_CACHE_DIR'] = 'my_tfhub_cache'\n","model = tf.keras.Sequential([\n","    hub.KerasLayer('https://tfhub.dev/google/universal-sentence-encoder/4', trainable=True, dtype=tf.string, input_shape=[]),\n","    tf.keras.layers.Dense(64, activation='relu'),\n","    tf.keras.layers.Dense(1, activation='sigmoid')\n","])\n","model.compile(loss='binary_crossentropy', optimizer='nadam', metrics=['accuracy'])\n","model.fit(train_set, validation_data=valid_set, epochs=10)"]},{"cell_type":"markdown","metadata":{"id":"6RNdUWwM8_A2"},"source":["## 16.3 신경망 기계 번역을 위한 인코더-디코더 네트워크"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1049,"status":"ok","timestamp":1698826889811,"user":{"displayName":"Hanjae Kim","userId":"02991760026987687501"},"user_tz":-540},"id":"sIWJ-6fJ8_A2","outputId":"922e7902-f99b-4378-a289-75ea1ffaeb1d"},"outputs":[],"source":["from pathlib import Path\n","\n","url = 'https://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip'\n","path = tf.keras.utils.get_file('spa-eng.zip', origin=url, cache_dir = 'datasets', extract=True)\n","text = (Path(path).with_name('spa-eng') / 'spa.txt').read_text()"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":594,"status":"ok","timestamp":1698826891203,"user":{"displayName":"Hanjae Kim","userId":"02991760026987687501"},"user_tz":-540},"id":"HZ00JpeQ8_A2"},"outputs":[],"source":["text = text.replace('i', '').replace('¿', '')\n","pairs = [line.split('\\t') for line in text.splitlines()]\n","np.random.shuffle(pairs)\n","sentences_en, sentences_es = zip(*pairs)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1698826891203,"user":{"displayName":"Hanjae Kim","userId":"02991760026987687501"},"user_tz":-540},"id":"_i1tXxfc8_A2","outputId":"f65ece19-2268-46a6-e5ac-94ce3e69f709"},"outputs":[{"name":"stdout","output_type":"stream","text":["Leave the room. => Leave the room.\n","Tom's novel has been translated nto French. => Tom's novel has been translated nto French.\n","The attempt faled. => The attempt faled.\n"]}],"source":["for i in range(3):\n","    print(sentences_en[i], '=>', sentences_en[i])"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":23995,"status":"ok","timestamp":1698826917087,"user":{"displayName":"Hanjae Kim","userId":"02991760026987687501"},"user_tz":-540},"id":"ZfngEqVS8_A2"},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-11-02 17:15:21.189361: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n","2023-11-02 17:15:26.549975: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"]}],"source":["vocab_size = 1000\n","max_length = 50\n","text_vec_layer_en = tf.keras.layers.TextVectorization(vocab_size, output_sequence_length=max_length)\n","text_vec_layer_es = tf.keras.layers.TextVectorization(vocab_size, output_sequence_length=max_length)\n","text_vec_layer_en.adapt(sentences_en)\n","text_vec_layer_es.adapt([f'startofseq {s} endofseq' for s in sentences_es])"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29,"status":"ok","timestamp":1698826917088,"user":{"displayName":"Hanjae Kim","userId":"02991760026987687501"},"user_tz":-540},"id":"VsYUa0wS8_A2","outputId":"614150c4-60a1-4cdc-af62-31d9032a98f3"},"outputs":[{"data":{"text/plain":["['', '[UNK]', 'the', 'i', 'to', 'you', 'tom', 'a', 's', 'he']"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["text_vec_layer_en.get_vocabulary()[:10]"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25,"status":"ok","timestamp":1698826917088,"user":{"displayName":"Hanjae Kim","userId":"02991760026987687501"},"user_tz":-540},"id":"YZ7w_SFw8_A2","outputId":"ff31b93e-82ea-436f-e52e-10ac13682980"},"outputs":[{"data":{"text/plain":["['', '[UNK]', 'startofseq', 'endofseq', 'de', 'que', 'a', 'no', 'tom', 'la']"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["text_vec_layer_es.get_vocabulary()[:10]"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":2348,"status":"ok","timestamp":1698826919414,"user":{"displayName":"Hanjae Kim","userId":"02991760026987687501"},"user_tz":-540},"id":"FqRtZxT28_A2"},"outputs":[],"source":["X_train = tf.constant(sentences_en[:100_000])\n","X_valid = tf.constant(sentences_en[100_000:])\n","X_train_dec = tf.constant([f'startofseq {s}' for s in sentences_es[:100_000]])\n","X_valid_dec = tf.constant([f'startofseq {s}' for s in sentences_es[100_000:]])\n","Y_train = text_vec_layer_es([f'{s} endofseq' for s in sentences_es[:100_000]])\n","Y_valid = text_vec_layer_es([f'{s} endofseq' for s in sentences_es[100_000:]])"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1698826919414,"user":{"displayName":"Hanjae Kim","userId":"02991760026987687501"},"user_tz":-540},"id":"89Aobvgg8_A2"},"outputs":[],"source":["encoder_inputs = tf.keras.layers.Input(shape=[], dtype=tf.string)\n","decoder_inputs = tf.keras.layers.Input(shape=[], dtype=tf.string)"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1698826919414,"user":{"displayName":"Hanjae Kim","userId":"02991760026987687501"},"user_tz":-540},"id":"MuGg7DDW8_A8"},"outputs":[],"source":["embed_size = 128\n","encoder_inputs_ids = text_vec_layer_en(encoder_inputs)\n","decoder_inputs_ids = text_vec_layer_es(decoder_inputs)\n","encoder_embedding_layer = tf.keras.layers.Embedding(vocab_size, embed_size, mask_zero=True)\n","decoder_embedding_layer = tf.keras.layers.Embedding(vocab_size, embed_size, mask_zero=True)\n","encoder_embeddings = encoder_embedding_layer(encoder_inputs_ids)\n","decoder_embeddings = decoder_embedding_layer(decoder_inputs_ids)"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":1025,"status":"ok","timestamp":1698826920437,"user":{"displayName":"Hanjae Kim","userId":"02991760026987687501"},"user_tz":-540},"id":"hYwz7aMq8_A9"},"outputs":[],"source":["encoder = tf.keras.layers.LSTM(512, return_state=True)\n","encoder_outputs, *encoder_state = encoder(encoder_embeddings)"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":1427,"status":"ok","timestamp":1698826921862,"user":{"displayName":"Hanjae Kim","userId":"02991760026987687501"},"user_tz":-540},"id":"7uigv6nV8_A9"},"outputs":[],"source":["decoder = tf.keras.layers.LSTM(512, return_sequences=True)\n","decoder_outputs = decoder(decoder_embeddings, initial_state=encoder_state)"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1698826921862,"user":{"displayName":"Hanjae Kim","userId":"02991760026987687501"},"user_tz":-540},"id":"noDqHi3N8_A9"},"outputs":[],"source":["output_layer = tf.keras.layers.Dense(vocab_size, activation='softmax')\n","Y_proba = output_layer(decoder_outputs)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SwxHQgfB8_A9","outputId":"bef05378-14b8-45b9-cde0-84046f4f9ff7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["2023-10-31 16:46:58.923879: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n","2023-10-31 16:46:59.553081: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n","type_id: TFT_OPTIONAL\n","args {\n","  type_id: TFT_PRODUCT\n","  args {\n","    type_id: TFT_TENSOR\n","    args {\n","      type_id: TFT_INT32\n","    }\n","  }\n","}\n"," is neither a subtype nor a supertype of the combined inputs preceding it:\n","type_id: TFT_OPTIONAL\n","args {\n","  type_id: TFT_PRODUCT\n","  args {\n","    type_id: TFT_TENSOR\n","    args {\n","      type_id: TFT_FLOAT\n","    }\n","  }\n","}\n","\n","\tfor Tuple type infernce function 0\n","\twhile inferring type of node 'cond_40/output/_23'\n","2023-10-31 16:46:59.557679: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n","2023-10-31 16:46:59.982819: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n","2023-10-31 16:47:00.316980: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n","2023-10-31 16:47:00.686237: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"]},{"name":"stdout","output_type":"stream","text":["3125/3125 [==============================] - ETA: 0s - loss: 3.5622 - accuracy: 0.3128"]},{"name":"stderr","output_type":"stream","text":["2023-10-31 16:51:18.478870: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n","2023-10-31 16:51:18.906063: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n","2023-10-31 16:51:19.107244: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"]},{"name":"stdout","output_type":"stream","text":["3125/3125 [==============================] - 282s 89ms/step - loss: 3.5622 - accuracy: 0.3128 - val_loss: 3.2777 - val_accuracy: 0.3311\n","Epoch 2/10\n","3125/3125 [==============================] - 278s 89ms/step - loss: 3.1824 - accuracy: 0.3404 - val_loss: 3.1375 - val_accuracy: 0.3491\n","Epoch 3/10\n","3125/3125 [==============================] - 299s 96ms/step - loss: 3.0445 - accuracy: 0.3535 - val_loss: 3.0796 - val_accuracy: 0.3469\n","Epoch 4/10\n","3125/3125 [==============================] - 354s 113ms/step - loss: 2.9549 - accuracy: 0.3586 - val_loss: 3.0378 - val_accuracy: 0.3519\n","Epoch 5/10\n","3125/3125 [==============================] - 326s 104ms/step - loss: 2.8692 - accuracy: 0.3681 - val_loss: 3.0184 - val_accuracy: 0.3562\n","Epoch 6/10\n","3125/3125 [==============================] - 332s 106ms/step - loss: 2.7860 - accuracy: 0.3788 - val_loss: 2.9517 - val_accuracy: 0.3685\n","Epoch 7/10\n","3125/3125 [==============================] - 328s 105ms/step - loss: 2.6612 - accuracy: 0.4017 - val_loss: 2.9375 - val_accuracy: 0.3754\n","Epoch 8/10\n","3125/3125 [==============================] - 3576s 1s/step - loss: 2.6302 - accuracy: 0.4049 - val_loss: 2.9672 - val_accuracy: 0.3719\n","Epoch 9/10\n","3125/3125 [==============================] - 262s 84ms/step - loss: 2.6049 - accuracy: 0.4033 - val_loss: 3.0372 - val_accuracy: 0.3560\n","Epoch 10/10\n","3125/3125 [==============================] - 293s 94ms/step - loss: 2.5475 - accuracy: 0.4104 - val_loss: 3.0583 - val_accuracy: 0.3533\n"]},{"data":{"text/plain":["<keras.src.callbacks.History at 0x1512ef610>"]},"execution_count":50,"metadata":{},"output_type":"execute_result"}],"source":["model = tf.keras.Model(inputs = [encoder_inputs, decoder_inputs], outputs = [Y_proba])\n","model.compile(loss = 'sparse_categorical_crossentropy', optimizer='nadam', metrics = ['accuracy'])\n","model.fit((X_train, X_train_dec), Y_train, epochs = 10, validation_data=((X_valid, X_valid_dec), Y_valid))"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1698828366289,"user":{"displayName":"Hanjae Kim","userId":"02991760026987687501"},"user_tz":-540},"id":"fte1LrEu8_A9"},"outputs":[],"source":["def translate(sentence_en):\n","    translation = ''\n","    for word_idx in range(max_length):\n","        X = np.array([sentence_en])\n","        X_dec = np.array(['startofseq ' + translation])\n","        y_proba = model.predict((X, X_dec))[0, word_idx]\n","        predicted_word_id = np.argmax(y_proba)\n","        predicted_word = text_vec_layer_es.get_vocabulary()[predicted_word_id]\n","        if predicted_word == 'endofseq':\n","            break\n","        translation += \" \" + predicted_word\n","    return translation.strip()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X28VQ2jK8_A9","outputId":"a84cb105-4f46-447c-8755-29b91f4a0be4"},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-10-31 18:32:28.783861: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n","2023-10-31 18:32:29.368715: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n","2023-10-31 18:32:29.658688: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"]},{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 2s 2s/step\n","1/1 [==============================] - 0s 56ms/step\n","1/1 [==============================] - 0s 77ms/step\n","1/1 [==============================] - 0s 59ms/step\n","1/1 [==============================] - 0s 41ms/step\n"]},{"data":{"text/plain":["'tom no [UNK] [UNK]'"]},"execution_count":52,"metadata":{},"output_type":"execute_result"}],"source":["translate(\"I like soccer\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gzCIwPFT8_A9","outputId":"2e06f898-f725-450a-b4c2-f971c394cc6d"},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 55ms/step\n","1/1 [==============================] - 0s 39ms/step\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 37ms/step\n"]},{"data":{"text/plain":["'tom no [UNK] [UNK]'"]},"execution_count":53,"metadata":{},"output_type":"execute_result"}],"source":["translate(\"I like soccer and also going to the beach\")"]},{"cell_type":"markdown","metadata":{"id":"32QCX7Av8_A9"},"source":["### 16.3.1 양방향 RNN"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qWmnHhWT8_A9"},"outputs":[],"source":["encoder = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256, return_state=True))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OTzrBSxB8_A9"},"outputs":[],"source":["encoder_outputs, *encoder_state = encoder(encoder_embeddings)\n","encoder_state = [tf.concat(encoder_state[::2], axis=-1),\n","                 tf.concat(encoder_state[1::2], axis=-1)]"]},{"cell_type":"markdown","metadata":{"id":"ov4Wkj2_8_A9"},"source":["### 16.3.2 빔 서치"]},{"cell_type":"markdown","metadata":{"id":"gOBwNVav8_A-"},"source":["## 16.4 어텐션 메커니즘"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1698826921862,"user":{"displayName":"Hanjae Kim","userId":"02991760026987687501"},"user_tz":-540},"id":"Ktg80kTc8_A-"},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-11-02 17:14:33.787042: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n","2023-11-02 17:14:33.787068: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n","2023-11-02 17:14:33.787076: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n","2023-11-02 17:14:33.787138: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n","2023-11-02 17:14:33.787170: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"]}],"source":["import tensorflow as tf\n","\n","tf.random.set_seed(42)\n","encoder = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256, return_sequences=True, return_state=True))"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":3247,"status":"ok","timestamp":1698826925105,"user":{"displayName":"Hanjae Kim","userId":"02991760026987687501"},"user_tz":-540},"id":"qNtDWN588_A-"},"outputs":[],"source":["encoder_outputs, *encoder_state = encoder(encoder_embeddings)\n","encoder_state = [tf.concat(encoder_state[::2], axis=-1),  # 단기 (0 & 2)\n","                 tf.concat(encoder_state[1::2], axis=-1)]  # 장기 (1 & 3)\n","decoder = tf.keras.layers.LSTM(512, return_sequences=True)\n","decoder_outputs = decoder(decoder_embeddings, initial_state=encoder_state)"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1698826925105,"user":{"displayName":"Hanjae Kim","userId":"02991760026987687501"},"user_tz":-540},"id":"uquj647D8_A-"},"outputs":[],"source":["attention_layer = tf.keras.layers.Attention()\n","attention_outputs = attention_layer([decoder_outputs, encoder_outputs])\n","\n","output_layer = tf.keras.layers.Dense(vocab_size, activation='softmax')\n","Y_proba = output_layer(attention_outputs)"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1055787,"status":"ok","timestamp":1698828007944,"user":{"displayName":"Hanjae Kim","userId":"02991760026987687501"},"user_tz":-540},"id":"K7gApYYn8_A-","outputId":"96981de8-4be5-470c-ea23-7b461bdc4fb6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","3125/3125 [==============================] - 142s 38ms/step - loss: 2.9484 - accuracy: 0.4420 - val_loss: 1.8391 - val_accuracy: 0.5964\n","Epoch 2/10\n","3125/3125 [==============================] - 97s 31ms/step - loss: 1.5628 - accuracy: 0.6446 - val_loss: 1.4477 - val_accuracy: 0.6654\n","Epoch 3/10\n","3125/3125 [==============================] - 94s 30ms/step - loss: 1.3003 - accuracy: 0.6900 - val_loss: 1.3296 - val_accuracy: 0.6869\n","Epoch 4/10\n","3125/3125 [==============================] - 98s 31ms/step - loss: 1.1583 - accuracy: 0.7159 - val_loss: 1.2838 - val_accuracy: 0.6959\n","Epoch 5/10\n","3125/3125 [==============================] - 99s 32ms/step - loss: 1.0536 - accuracy: 0.7356 - val_loss: 1.2593 - val_accuracy: 0.7039\n","Epoch 6/10\n","3125/3125 [==============================] - 94s 30ms/step - loss: 0.9661 - accuracy: 0.7528 - val_loss: 1.2580 - val_accuracy: 0.7058\n","Epoch 7/10\n","3125/3125 [==============================] - 97s 31ms/step - loss: 0.8916 - accuracy: 0.7682 - val_loss: 1.2697 - val_accuracy: 0.7035\n","Epoch 8/10\n","3125/3125 [==============================] - 93s 30ms/step - loss: 0.8268 - accuracy: 0.7819 - val_loss: 1.2871 - val_accuracy: 0.7057\n","Epoch 9/10\n","3125/3125 [==============================] - 93s 30ms/step - loss: 0.7716 - accuracy: 0.7940 - val_loss: 1.3137 - val_accuracy: 0.7058\n","Epoch 10/10\n","3125/3125 [==============================] - 89s 28ms/step - loss: 0.7225 - accuracy: 0.8049 - val_loss: 1.3387 - val_accuracy: 0.7056\n"]},{"data":{"text/plain":["<keras.src.callbacks.History at 0x7b2b7b374c10>"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["model = tf.keras.Model(inputs = [encoder_inputs, decoder_inputs], outputs=[Y_proba])\n","model.compile(loss = 'sparse_categorical_crossentropy', optimizer='nadam', metrics=['accuracy'])\n","model.fit((X_train, X_train_dec), Y_train, epochs=10, validation_data = ((X_valid, X_valid_dec), Y_valid))"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":214},"executionInfo":{"elapsed":5550,"status":"ok","timestamp":1698828376015,"user":{"displayName":"Hanjae Kim","userId":"02991760026987687501"},"user_tz":-540},"id":"BgyMQY4M8_A-","outputId":"23cf2bda-c78f-4d6e-f21f-18082dd2de30"},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 5s 5s/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 29ms/step\n"]},{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'yo yo [UNK] fútbol y tambén [UNK] la playa'"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["translate(\"I like soccer and also going to the beach\")"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":982},"executionInfo":{"elapsed":3792,"status":"ok","timestamp":1698828383480,"user":{"displayName":"Hanjae Kim","userId":"02991760026987687501"},"user_tz":-540},"id":"JVvK130T8_A-","outputId":"23d3914c-a959-4c1a-de9f-3d94c5e3cd11"},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 27ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 27ms/step\n"]},{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'[UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]'"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["translate(\"hello!\")"]},{"cell_type":"markdown","metadata":{"id":"8-6Rb7rz8_A-"},"source":["### 16.4.1 트랜스포머 구조: 어텐션만 있으면 된다"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["max_length = 50\n","embed_size = 128\n","pos_embed_layer = tf.keras.layers.Embedding(max_length, embed_size)\n","batch_max_len_enc = tf.shape(encoder_embeddings)[1]\n","encoder_in = encoder_embeddings + pos_embed_layer(tf.range(batch_max_len_enc))\n","batch_max_len_dec = tf.shape(decoder_embeddings)[1]\n","decoder_in = decoder_embeddings + pos_embed_layer(tf.range(batch_max_len_dec))"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[],"source":["class PositionalEncoding(tf.keras.layers.Layer):\n","    def __init__(self, max_length, embed_size, dtype=tf.float32, **kwargs):\n","        super().__init__(dtype=dtype, **kwargs)\n","        assert embed_size % 2 == 0, \"embed_size must be even\"\n","        p, i = np.meshgrid(np.arange(max_length),\n","                           2 * np.arange(embed_size // 2))\n","        pos_emb = np.empty((1, max_length, embed_size))\n","        pos_emb[0, :, ::2] = np.sin(p / 10_000 ** (i / embed_size)).T\n","        pos_emb[0, :, 1::2] = np.cos(p / 10_000 ** (i / embed_size)).T\n","        self.pos_encodings = tf.constant(pos_emb.astype(self.dtype))\n","        self.supports_masking = True\n","\n","    def call(self, inputs):\n","        batch_max_length = tf.shape(inputs)[1]\n","        return inputs + self.pos_encodings[:, :batch_max_length]"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["pos_embed_layer = PositionalEncoding(max_length, embed_size)\n","encoder_in = pos_embed_layer(encoder_embeddings)\n","decoder_in = pos_embed_layer(decoder_embeddings)"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[],"source":["N = 2\n","num_heads = 8\n","dropout_rate = 0.1\n","n_units = 128\n","encoder_pad_mask = tf.math.not_equal(encoder_inputs_ids, 0)[:, tf.newaxis]\n","Z = encoder_in\n","for _ in range(N):\n","    skip = Z\n","    attn_layer = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_size, dropout=dropout_rate)\n","    Z = attn_layer(Z, value=Z, attention_mask = encoder_pad_mask)\n","    Z = tf.keras.layers.LayerNormalization()(tf.keras.layers.Add()([Z, skip]))\n","    skip = Z\n","    Z = tf.keras.layers.Dense(n_units, activation='relu')(Z)\n","    Z = tf.keras.layers.Dense(embed_size)(Z)\n","    Z = tf.keras.layers.Dropout(dropout_rate)(Z)\n","    Z = tf.keras.layers.LayerNormalization()(tf.keras.layers.Add()([Z, skip]))"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["decoder_pad_mask = tf.math.not_equal(decoder_inputs_ids, 0)[:, tf.newaxis]\n","causal_mask = tf.linalg.band_part(tf.ones((batch_max_len_dec, batch_max_len_dec), tf.bool), -1, 0)"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[],"source":["encoder_outputs = Z\n","Z = decoder_in\n","for _ in range(N):\n","    skip = Z\n","    attn_layer = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_size, dropout=dropout_rate)\n","    Z = attn_layer(Z, value=Z, attention_mask = causal_mask & decoder_pad_mask)\n","    Z = tf.keras.layers.LayerNormalization()(tf.keras.layers.Add()([Z, skip]))\n","    skip = Z\n","    attn_layer = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_size, dropout=dropout_rate)\n","    Z = attn_layer(Z, value=encoder_outputs, attention_mask = encoder_pad_mask)\n","    Z = tf.keras.layers.LayerNormalization()(tf.keras.layers.Add()([Z, skip]))\n","    skip = Z\n","    Z = tf.keras.layers.Dense(n_units, activation='relu')(Z)\n","    Z = tf.keras.layers.Dense(embed_size)(Z)\n","    Z = tf.keras.layers.LayerNormalization()(tf.keras.layers.Add()([Z, skip]))"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["2023-11-02 19:47:15.318360: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"]},{"name":"stdout","output_type":"stream","text":["   9/3125 [..............................] - ETA: 1:05:18 - loss: 5.8682 - accuracy: 0.1394"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m/Users/oneash/ONEASH/Coding/HandsOnML/codes/16_nlp_with_rnns_and_attention.ipynb Cell 66\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/oneash/ONEASH/Coding/HandsOnML/codes/16_nlp_with_rnns_and_attention.ipynb#Y125sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mModel(inputs\u001b[39m=\u001b[39m[encoder_inputs, decoder_inputs], outputs \u001b[39m=\u001b[39m [Y_proba])\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/oneash/ONEASH/Coding/HandsOnML/codes/16_nlp_with_rnns_and_attention.ipynb#Y125sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msparse_categorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m, optimizer \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mnadam\u001b[39m\u001b[39m'\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/oneash/ONEASH/Coding/HandsOnML/codes/16_nlp_with_rnns_and_attention.ipynb#Y125sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit((X_train, X_train_dec), Y_train, epochs \u001b[39m=\u001b[39;49m \u001b[39m10\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m((X_valid, X_valid_dec), Y_valid))\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1743\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    149\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function(\u001b[39m*\u001b[39;49margs))\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    197\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    198\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[1;32m    199\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[1;32m    200\u001b[0m     )\n\u001b[1;32m    201\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\u001b[39mself\u001b[39m, \u001b[39mlist\u001b[39m(args))\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m   1458\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1459\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[1;32m   1460\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[1;32m   1461\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m   1462\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1463\u001b[0m   )\n\u001b[1;32m   1464\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["Y_proba = tf.keras.layers.Dense(vocab_size, activation='softmax')(Z)\n","model = tf.keras.Model(inputs=[encoder_inputs, decoder_inputs], outputs = [Y_proba])\n","model.compile(loss='sparse_categorical_crossentropy', optimizer = 'nadam', metrics=['accuracy'])\n","model.fit((X_train, X_train_dec), Y_train, epochs = 10, validation_data=((X_valid, X_valid_dec), Y_valid))"]},{"cell_type":"markdown","metadata":{},"source":["## 16.5 언어 모델 분야의 최근 혁신"]},{"cell_type":"markdown","metadata":{},"source":["## 16.6 비전 트랜스포머"]},{"cell_type":"markdown","metadata":{},"source":["## 16.7 허깅 페이스의 트랜스포머스 라이브러리"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n","Using a pipeline without specifying a model name and revision in production is not recommended.\n"]},{"data":{"text/plain":["[{'label': 'POSITIVE', 'score': 0.9998071789741516}]"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["from transformers import pipeline\n","\n","classifier = pipeline('sentiment-analysis')\n","result = classifier('The actors were very convincing.')\n","result"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"data":{"text/plain":["[{'label': 'POSITIVE', 'score': 0.9896161556243896},\n"," {'label': 'NEGATIVE', 'score': 0.9811071157455444}]"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["classifier(['I am from India.', 'I am from Iraq.'])"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"88339617ee1141bb934df290bebcded6","version_major":2,"version_minor":0},"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/729 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2685cdc5c7a9460598907e91d6d2bac0","version_major":2,"version_minor":0},"text/plain":["Downloading model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"05c73aa531574b698886e5f0bcec4007","version_major":2,"version_minor":0},"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/58.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d1909f02b5f34e0487baa8e03235b4e8","version_major":2,"version_minor":0},"text/plain":["Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7579f9a5e8804b22b8c808b1da174092","version_major":2,"version_minor":0},"text/plain":["Downloading (…)in/added_tokens.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b04b76ff0ad1477c84d042259ff0530d","version_major":2,"version_minor":0},"text/plain":["Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["[{'label': 'contradiction', 'score': 0.6888487935066223}]"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["model_name = 'huggingface/distilbert-base-uncased-finetuned-mnli'\n","classifier_mnli = pipeline('text-classification', model=model_name)\n","classifier_mnli('She loves me. [SEP] She loves me not')"]},{"cell_type":"markdown","metadata":{},"source":["## 16.8 연습문제"]},{"cell_type":"markdown","metadata":{},"source":["### 8"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["import tensorflow as tf\n","import numpy as np"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["default_reber_grammar = [\n","    [(\"B\", 1)],           # (state 0) =B=>(state 1)\n","    [(\"T\", 2), (\"P\", 3)], # (state 1) =T=>(state 2) or =P=>(state 3)\n","    [(\"S\", 2), (\"X\", 4)], # (state 2) =S=>(state 2) or =X=>(state 4)\n","    [(\"T\", 3), (\"V\", 5)], # 등등 ...\n","    [(\"X\", 3), (\"S\", 6)],\n","    [(\"P\", 4), (\"V\", 6)],\n","    [(\"E\", None)]]        # (state 6) =E=>(terminal state)\n","\n","embedded_reber_grammar = [\n","    [(\"B\", 1)],\n","    [(\"T\", 2), (\"P\", 3)],\n","    [(default_reber_grammar, 4)],\n","    [(default_reber_grammar, 5)],\n","    [(\"T\", 6)],\n","    [(\"P\", 6)],\n","    [(\"E\", None)]]\n","\n","def generate_string(grammar):\n","    state = 0\n","    output = []\n","    while state is not None:\n","        index = np.random.randint(len(grammar[state]))\n","        production, state = grammar[state][index]\n","        if isinstance(production, list):\n","            production = generate_string(grammar=production)\n","        output.append(production)\n","    return \"\".join(output)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["BTXXTTVPXTVPXTTVPSE BPVPSE BTXSE BPVVE BPVVE BTSXSE BPTVPXTTTVVE BPVVE BTXSE BTXXVPSE BPTTTTTTTTVVE BTXSE BPVPSE BTXSE BPTVPSE BTXXTVPSE BPVVE BPVVE BPVVE BPTTVVE BPVVE BPVVE BTXXVVE BTXXVVE BTXXVPXVVE "]}],"source":["np.random.seed(42)\n","\n","for _ in range(25):\n","    print(generate_string(default_reber_grammar), end = \" \")"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["BTBPTTTVPXTVPXTTVPSETE BPBPTVPSEPE BPBPVVEPE BPBPVPXVVEPE BPBTXXTTTTVVEPE BPBPVPSEPE BPBTXXVPSEPE BPBTSSSSSSSXSEPE BTBPVVETE BPBTXXVVEPE BPBTXXVPSEPE BTBTXXVVETE BPBPVVEPE BPBPVVEPE BPBTSXSEPE BPBPVVEPE BPBPTVPSEPE BPBTXXVVEPE BTBPTVPXVVETE BTBPVVETE BTBTSSSSSSSXXVVETE BPBTSSSXXTTTTVPSEPE BTBPTTVVETE BPBTXXTVVEPE BTBTXSETE "]}],"source":["np.random.seed(42)\n","\n","for _ in range(25):\n","    print(generate_string(embedded_reber_grammar), end=\" \")"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[],"source":["POSSIBLE_CHARS = \"BEPSTVX\"\n","\n","def generate_corrupted_string(grammar, chars=POSSIBLE_CHARS):\n","    good_string = generate_string(grammar)\n","    index = np.random.randint(len(good_string))\n","    good_char = good_string[index]\n","    bad_char = np.random.choice(sorted(set(chars) - set(good_char)))\n","    return good_string[:index] + bad_char + good_string[index + 1:]\n"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["BTBPTTTPPXTVPXTTVPSETE BPBTXEEPE BPBPTVVVEPE BPBTSSSSXSETE BPTTXSEPE BTBPVPXTTTTTTEVETE BPBTXXSVEPE BSBPTTVPSETE BPBXVVEPE BEBTXSETE BPBPVPSXPE BTBPVVVETE BPBTSXSETE BPBPTTTPTTTTTVPSEPE BTBTXXTTSTVPSETE BBBTXSETE BPBTPXSEPE BPBPVPXTTTTVPXTVPXVPXTTTVVEVE BTBXXXTVPSETE BEBTSSSSSXXVPXTVVETE BTBXTTVVETE BPBTXSTPE BTBTXXTTTVPSBTE BTBTXSETX BTBTSXSSTE "]}],"source":["np.random.seed(42)\n","\n","for _ in range(25):\n","    print(generate_corrupted_string(embedded_reber_grammar), end=\" \")"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[],"source":["def string_to_ids(s, chars=POSSIBLE_CHARS):\n","    return [chars.index(c) for c in s]"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[{"data":{"text/plain":["[0, 4, 4, 4, 6, 6, 5, 5, 1, 4, 1]"]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["string_to_ids(\"BTTTXXVVETE\")"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[],"source":["def generate_dataset(size):\n","    good_strings = [\n","        string_to_ids(generate_string(embedded_reber_grammar))\n","        for _ in range(size // 2)\n","    ]\n","    bad_strings = [\n","        string_to_ids(generate_corrupted_string(embedded_reber_grammar))\n","        for _ in range(size - size // 2)\n","    ]\n","    all_strings = good_strings + bad_strings\n","    X = tf.ragged.constant(all_strings, ragged_rank=1)\n","    y = np.array([[1.] for _ in range(len(good_strings))] +\n","                 [[0.] for _ in range(len(bad_strings))])\n","    return X, y"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[],"source":["np.random.seed(42)\n","\n","X_train, y_train = generate_dataset(10000)\n","X_valid, y_valid = generate_dataset(2000)"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/20\n"]},{"name":"stderr","output_type":"stream","text":["2023-11-05 17:06:07.574295: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node SGD/AssignVariableOp_1.\n"]},{"name":"stdout","output_type":"stream","text":[" 13/313 [>.............................] - ETA: 43s - loss: 0.6934 - accuracy: 0.4736"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m/Users/oneash/ONEASH/Coding/HandsOnML/codes/16_nlp_with_rnns_and_attention.ipynb Cell 85\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/oneash/ONEASH/Coding/HandsOnML/codes/16_nlp_with_rnns_and_attention.ipynb#Y153sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m optimizer \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mSGD(learning_rate\u001b[39m=\u001b[39m\u001b[39m0.02\u001b[39m, momentum \u001b[39m=\u001b[39m \u001b[39m0.95\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/oneash/ONEASH/Coding/HandsOnML/codes/16_nlp_with_rnns_and_attention.ipynb#Y153sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m                                     nesterov\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/oneash/ONEASH/Coding/HandsOnML/codes/16_nlp_with_rnns_and_attention.ipynb#Y153sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbinary_crossentropy\u001b[39m\u001b[39m\"\u001b[39m, optimizer\u001b[39m=\u001b[39moptimizer,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/oneash/ONEASH/Coding/HandsOnML/codes/16_nlp_with_rnns_and_attention.ipynb#Y153sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m               metrics\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/oneash/ONEASH/Coding/HandsOnML/codes/16_nlp_with_rnns_and_attention.ipynb#Y153sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X_train, y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/oneash/ONEASH/Coding/HandsOnML/codes/16_nlp_with_rnns_and_attention.ipynb#Y153sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m                     validation_data\u001b[39m=\u001b[39;49m(X_valid, y_valid))\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/engine/training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1775\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1776\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1777\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1780\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1781\u001b[0m ):\n\u001b[1;32m   1782\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1783\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1784\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1785\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    828\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 831\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    833\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    834\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    864\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    865\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    866\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 867\u001b[0m   \u001b[39mreturn\u001b[39;00m tracing_compilation\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    868\u001b[0m       args, kwds, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_config\n\u001b[1;32m    869\u001b[0m   )\n\u001b[1;32m    870\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_config \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    872\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mbind(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[39mreturn\u001b[39;00m function\u001b[39m.\u001b[39;49m_call_flat(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[39m=\u001b[39;49mfunction\u001b[39m.\u001b[39;49mcaptured_inputs\n\u001b[1;32m    141\u001b[0m )\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1260\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1261\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1262\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1263\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1264\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mflat_call(args)\n\u001b[1;32m   1265\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1266\u001b[0m     args,\n\u001b[1;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1268\u001b[0m     executing_eagerly)\n\u001b[1;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mflat_call\u001b[39m(\u001b[39mself\u001b[39m, args: Sequence[core\u001b[39m.\u001b[39mTensor]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    216\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m   flat_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    218\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mpack_output(flat_outputs)\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[1;32m    251\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 252\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    253\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    254\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[1;32m    255\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[1;32m    256\u001b[0m     )\n\u001b[1;32m    257\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    259\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m    260\u001b[0m         \u001b[39mlist\u001b[39m(args),\n\u001b[1;32m    261\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mfunction_call_options\u001b[39m.\u001b[39mas_attrs(),\n\u001b[1;32m    262\u001b[0m     )\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[1;32m   1478\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1479\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m   1480\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1481\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[1;32m   1482\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[1;32m   1483\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m   1484\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1485\u001b[0m   )\n\u001b[1;32m   1486\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1487\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1488\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1489\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1493\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[1;32m   1494\u001b[0m   )\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[39m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m   inputs \u001b[39m=\u001b[39m [\n\u001b[1;32m     55\u001b[0m       tensor_conversion_registry\u001b[39m.\u001b[39mconvert(t)\n\u001b[1;32m     56\u001b[0m       \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, core_types\u001b[39m.\u001b[39mTensor)\n\u001b[1;32m     57\u001b[0m       \u001b[39melse\u001b[39;00m t\n\u001b[1;32m     58\u001b[0m       \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m inputs\n\u001b[1;32m     59\u001b[0m   ]\n\u001b[0;32m---> 60\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     61\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     62\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     63\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["np.random.seed(42)\n","tf.random.set_seed(42)\n","\n","embedding_size = 5\n","\n","model = tf.keras.Sequential([\n","    tf.keras.layers.InputLayer(input_shape=[None], dtype=tf.int32, ragged=True),\n","    tf.keras.layers.Embedding(input_dim=len(POSSIBLE_CHARS),\n","                              output_dim=embedding_size),\n","    tf.keras.layers.GRU(30),\n","    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n","])\n","optimizer = tf.keras.optimizers.SGD(learning_rate=0.02, momentum = 0.95,\n","                                    nesterov=True)\n","model.compile(loss=\"binary_crossentropy\", optimizer=optimizer,\n","              metrics=[\"accuracy\"])\n","history = model.fit(X_train, y_train, epochs=20,\n","                    validation_data=(X_valid, y_valid))"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 70ms/step\n","\n","레버 문자열일 추정 확률:\n","BPBTSSSSSSSXXTTVPXVPXTTTTTVVETE: nan%\n","BPBTSSSSSSSXXTTVPXVPXTTTTTVVEPE: nan%\n"]}],"source":["test_strings = [\"BPBTSSSSSSSXXTTVPXVPXTTTTTVVETE\",\n","                \"BPBTSSSSSSSXXTTVPXVPXTTTTTVVEPE\"]\n","X_test = tf.ragged.constant([string_to_ids(s) for s in test_strings], ragged_rank=1)\n","\n","y_proba = model.predict(X_test)\n","print()\n","print(\"레버 문자열일 추정 확률:\")\n","for index, string in enumerate(test_strings):\n","    print(\"{}: {:.2f}%\".format(string, 100 * y_proba[index][0]))"]},{"cell_type":"markdown","metadata":{},"source":["### 9"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["from datetime import date\n","\n","MONTHS = [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"]\n","\n","def random_dates(n_dates):\n","    min_date = date(1000, 1, 1).toordinal()\n","    max_date = date(9999, 12, 31).toordinal()\n","    ordinals = np.random.randint(max_date - min_date, size=n_dates) + min_date\n","    dates = [date.fromordinal(ordinal) for ordinal in ordinals]\n","\n","    x = [MONTHS[dt.month - 1] + \" \" + dt.strftime(\"%d, %Y\") for dt in dates]\n","    y = [dt.isoformat() for dt in dates]\n","    return x, y\n"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Input                    Target                   \n","--------------------------------------------------\n","September 20, 7075       7075-09-20               \n","May 15, 8579             8579-05-15               \n","January 11, 7103         7103-01-11               \n"]}],"source":["np.random.seed(42)\n","\n","n_dates = 3\n","x_example, y_example = random_dates(n_dates)\n","print(\"{:25s}{:25s}\".format(\"Input\", \"Target\"))\n","print(\"-\" * 50)\n","for idx in range(n_dates):\n","    print(\"{:25s}{:25s}\".format(x_example[idx], y_example[idx]))"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"data":{"text/plain":["' ,0123456789ADFJMNOSabceghilmnoprstuvy'"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["INPUT_CHARS = ''.join(sorted(set(''.join(MONTHS) + '0123456789, ')))\n","INPUT_CHARS"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["OUTPUT_CHARS = '0123456789-'"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["def date_str_to_ids(date_str, chars=INPUT_CHARS):\n","    return [chars.index(c) for c in date_str]"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"data":{"text/plain":["[19, 23, 31, 34, 23, 28, 21, 23, 32, 0, 4, 2, 1, 0, 9, 2, 9, 7]"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["date_str_to_ids(x_example[0], INPUT_CHARS)"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"data":{"text/plain":["[7, 0, 7, 5, 10, 0, 9, 10, 2, 0]"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["date_str_to_ids(y_example[0], OUTPUT_CHARS)"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[],"source":["def prepare_date_strs(date_strs, chars=INPUT_CHARS):\n","    X_ids = [date_str_to_ids(dt, chars) for dt in date_strs]\n","    X = tf.ragged.constant(X_ids, ragged_rank=1)\n","    return (X + 1).to_tensor()\n","\n","def create_dataset(n_dates):\n","    x, y = random_dates(n_dates)\n","    return prepare_date_strs(x, INPUT_CHARS), prepare_date_strs(y, OUTPUT_CHARS)"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["np.random.seed(42)\n","\n","X_train, Y_train = create_dataset(10000)\n","X_valid, Y_valid = create_dataset(2000)\n","X_test, Y_test = create_dataset(2000)"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 8,  1,  8,  6, 11,  1, 10, 11,  3,  1], dtype=int32)>"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["Y_train[0]"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Nadam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Nadam`.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/20\n"]},{"name":"stderr","output_type":"stream","text":["2023-11-06 17:04:00.111511: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"]},{"name":"stdout","output_type":"stream","text":["313/313 [==============================] - 15s 36ms/step - loss: 1.7095 - accuracy: 0.3825 - val_loss: 1.3277 - val_accuracy: 0.5161\n","Epoch 2/20\n","313/313 [==============================] - 10s 32ms/step - loss: 1.1621 - accuracy: 0.5811 - val_loss: 0.9958 - val_accuracy: 0.6339\n","Epoch 3/20\n","313/313 [==============================] - 10s 32ms/step - loss: 0.8306 - accuracy: 0.6944 - val_loss: 0.6976 - val_accuracy: 0.7361\n","Epoch 4/20\n","313/313 [==============================] - 10s 33ms/step - loss: 0.6029 - accuracy: 0.7591 - val_loss: 0.5310 - val_accuracy: 0.7819\n","Epoch 5/20\n","313/313 [==============================] - 11s 35ms/step - loss: 0.6524 - accuracy: 0.7568 - val_loss: 0.4415 - val_accuracy: 0.8218\n","Epoch 6/20\n","313/313 [==============================] - 11s 34ms/step - loss: 0.3517 - accuracy: 0.8597 - val_loss: 0.2902 - val_accuracy: 0.8862\n","Epoch 7/20\n","313/313 [==============================] - 11s 36ms/step - loss: 0.2383 - accuracy: 0.9137 - val_loss: 0.2001 - val_accuracy: 0.9334\n","Epoch 8/20\n","313/313 [==============================] - 10s 33ms/step - loss: 0.1608 - accuracy: 0.9521 - val_loss: 0.1186 - val_accuracy: 0.9692\n","Epoch 9/20\n","313/313 [==============================] - 11s 35ms/step - loss: 0.0880 - accuracy: 0.9799 - val_loss: 0.0902 - val_accuracy: 0.9775\n","Epoch 10/20\n","313/313 [==============================] - 11s 34ms/step - loss: 0.7756 - accuracy: 0.7587 - val_loss: 0.3099 - val_accuracy: 0.9132\n","Epoch 11/20\n","313/313 [==============================] - 12s 38ms/step - loss: 0.1938 - accuracy: 0.9566 - val_loss: 0.1226 - val_accuracy: 0.9789\n","Epoch 12/20\n","313/313 [==============================] - 11s 35ms/step - loss: 0.0826 - accuracy: 0.9892 - val_loss: 0.0601 - val_accuracy: 0.9926\n","Epoch 13/20\n","313/313 [==============================] - 11s 37ms/step - loss: 0.0433 - accuracy: 0.9960 - val_loss: 0.0350 - val_accuracy: 0.9971\n","Epoch 14/20\n","313/313 [==============================] - 12s 37ms/step - loss: 0.0258 - accuracy: 0.9983 - val_loss: 0.0226 - val_accuracy: 0.9980\n","Epoch 15/20\n","313/313 [==============================] - 10s 32ms/step - loss: 0.0169 - accuracy: 0.9991 - val_loss: 0.0158 - val_accuracy: 0.9992\n","Epoch 16/20\n","313/313 [==============================] - 10s 32ms/step - loss: 0.0115 - accuracy: 0.9996 - val_loss: 0.0106 - val_accuracy: 0.9995\n","Epoch 17/20\n","313/313 [==============================] - 11s 35ms/step - loss: 0.0083 - accuracy: 0.9998 - val_loss: 0.0079 - val_accuracy: 0.9998\n","Epoch 18/20\n","313/313 [==============================] - 10s 33ms/step - loss: 0.0060 - accuracy: 0.9999 - val_loss: 0.0061 - val_accuracy: 0.9999\n","Epoch 19/20\n","313/313 [==============================] - 10s 32ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 0.9999\n","Epoch 20/20\n","313/313 [==============================] - 10s 32ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9999\n"]}],"source":["embedding_size = 32\n","max_output_length = Y_train.shape[1]\n","\n","np.random.seed(42)\n","tf.random.set_seed(42)\n","\n","encoder = tf.keras.Sequential([\n","    tf.keras.layers.Embedding(input_dim = len(INPUT_CHARS) + 1, output_dim = embedding_size, input_shape = [None]),\n","    tf.keras.layers.LSTM(128)\n","])\n","\n","decoder = tf.keras.Sequential([\n","    tf.keras.layers.LSTM(128, return_sequences=True),\n","    tf.keras.layers.Dense(len(OUTPUT_CHARS) + 1, activation='softmax')\n","])\n","\n","model = tf.keras.Sequential([\n","    encoder,\n","    tf.keras.layers.RepeatVector(max_output_length),\n","    decoder\n","])\n","\n","optimizer = tf.keras.optimizers.Nadam()\n","model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n","history = model.fit(X_train, Y_train, epochs=20, validation_data=(X_valid, Y_valid))"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[],"source":["def ids_to_date_strs(ids, chars=OUTPUT_CHARS):\n","    return [\"\".join([('?' + chars)[index] for index in sequence]) for sequence in ids]"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[],"source":["X_new = prepare_date_strs(['September 17, 2009', 'July 14, 1789'])"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 1s 563ms/step\n","2009-09-17\n","1789-07-14\n"]}],"source":["ids = model.predict(X_new).argmax(axis=-1)\n","for date_str in ids_to_date_strs(ids):\n","    print(date_str)"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 483ms/step\n","2020-02-02\n","1789-02-14\n"]}],"source":["X_new = prepare_date_strs([\"May 02, 2020\", \"July 14, 1789\"])\n","ids = model.predict(X_new).argmax(axis=-1)\n","for date_str in ids_to_date_strs(ids):\n","    print(date_str)"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[],"source":["max_input_length = X_train.shape[1]\n","\n","def prepare_date_strs_padded(date_strs):\n","    X = prepare_date_strs(date_strs)\n","    if X.shape[1] < max_input_length:\n","        X = tf.pad(X, [[0, 0], [0, max_input_length - X.shape[1]]])\n","    return X\n","\n","def convert_date_strs(date_strs):\n","    X = prepare_date_strs_padded(date_strs)\n","    ids = model.predict(X).argmax(axis=-1)\n","    return ids_to_date_strs(ids)"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 44ms/step\n"]},{"data":{"text/plain":["['2020-05-02', '1789-07-14']"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["convert_date_strs([\"May 02, 2020\", \"July 14, 1789\"])"]},{"cell_type":"markdown","metadata":{},"source":["### 11"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7a48f95a633c4762b9ea3e528b18a6a3","version_major":2,"version_minor":0},"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/656 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"29b4e449d5aa46d5b2af76891a047b19","version_major":2,"version_minor":0},"text/plain":["Downloading model.safetensors:   0%|          | 0.00/479M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFOpenAIGPTLMHeadModel: ['h.5.attn.bias', 'h.2.attn.bias', 'h.11.attn.bias', 'h.9.attn.bias', 'h.4.attn.bias', 'h.1.attn.bias', 'h.6.attn.bias', 'h.3.attn.bias', 'h.10.attn.bias', 'h.8.attn.bias', 'h.7.attn.bias', 'h.0.attn.bias']\n","- This IS expected if you are initializing TFOpenAIGPTLMHeadModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFOpenAIGPTLMHeadModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFOpenAIGPTLMHeadModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFOpenAIGPTLMHeadModel for predictions without further training.\n"]}],"source":["from transformers import TFOpenAIGPTLMHeadModel\n","\n","model = TFOpenAIGPTLMHeadModel.from_pretrained('openai-gpt')"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d5771d3f146145939db39d774a56a396","version_major":2,"version_minor":0},"text/plain":["Downloading (…)olve/main/vocab.json:   0%|          | 0.00/816k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6d741ed9594c4a8db4570855435cfb23","version_major":2,"version_minor":0},"text/plain":["Downloading (…)olve/main/merges.txt:   0%|          | 0.00/458k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2345f29f8c1a462caa1517f00dfad030","version_major":2,"version_minor":0},"text/plain":["Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.27M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["ftfy or spacy is not installed using BERT BasicTokenizer instead of SpaCy & ftfy.\n"]}],"source":["from transformers import OpenAIGPTTokenizer\n","\n","tokenizer = OpenAIGPTTokenizer.from_pretrained('openai-gpt')"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[{"data":{"text/plain":["{'input_ids': [3570, 1473], 'attention_mask': [1, 1]}"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer('hello everyone')"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(1, 10), dtype=int32, numpy=\n","array([[  616,  5751,  6404,   498,  9606,   240,   616, 26271,  7428,\n","        16187]], dtype=int32)>"]},"execution_count":42,"metadata":{},"output_type":"execute_result"}],"source":["prompt_text = 'This royal throne of kings, this sceptred isle'\n","encoded_prompt = tokenizer.encode(prompt_text, add_special_tokens=False, return_tensors='tf')\n","encoded_prompt"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(5, 50), dtype=int32, numpy=\n","array([[  616,  5751,  6404,   498,  9606,   240,   616, 26271,  7428,\n","        16187,   239, 40477,   556,   524,  1724,  4338,   504,   481,\n","          831,  1520,   546,   535, 12003,  4374,   240, 10341,   535,\n","         2236,  1404, 21760,   239,   998,   524,  2170,  1063,  1098,\n","          833,   604, 21617,   575,   240,   524,  9093,   626,   595,\n","         4203,  1129,   239,   487,  1787],\n","       [  616,  5751,  6404,   498,  9606,   240,   616, 26271,  7428,\n","        16187,   636,  1300,   666,   246, 12065,  1276,   240,   488,\n","          557,   622, 14404,  1546,  1260,   481, 19995,   240, 14404,\n","        30599,   636,  3226,   239,   500,   616,   638,   507,   509,\n","         1816,   525,  1007,  1594,   636,  1443,   580,  1632,   240,\n","          481,  6391,  7876,   498,   481],\n","       [  616,  5751,  6404,   498,  9606,   240,   616, 26271,  7428,\n","        16187,   239,   645,   512,   640,   246,  1250,   498,   547,\n","         3766,   488,   595,   547,  1662,   240,   674,  4055,   704,\n","         1254,   239,   256, 40477,   256,   249,   604,   664,  3367,\n","          500, 32883,   246,  7339,   525,  1222,   964,  1038,   568,\n","          485,  5018,   240,   256,   487],\n","       [  616,  5751,  6404,   498,  9606,   240,   616, 26271,  7428,\n","        16187,   240,   544,   481,  8018,   618,   498, 37736,   240,\n","          616,  1546,   544,   481,  1432,  2636,   500,   481,  9687,\n","          240,   488,   616,  1546,   544,   563, 15198,  2303,   702,\n","          246,   762,   260,   498,   260,  2557,   240,   246, 26090,\n","          531, 17378,   240,   246,  3128],\n","       [  616,  5751,  6404,   498,  9606,   240,   616, 26271,  7428,\n","        16187,   240,   812,   580,  3232,   239,   512,   804,   580,\n","          481,  2093,   498,   246,   618,   239,   512,   804,  2985,\n","          547,  7047,   488,   580,   547,  2093,   239,   256, 40477,\n","          481,   618,   816,   714,   491,   524,  1712,   239, 40477,\n","          256,   512,   761,   246, 19456]], dtype=int32)>"]},"execution_count":43,"metadata":{},"output_type":"execute_result"}],"source":["num_sequences = 5\n","length = 40\n","\n","generated_sequences = model.generate(\n","    input_ids = encoded_prompt, \n","    do_sample = True,\n","    max_length = length + len(encoded_prompt[0]),\n","    temperature = 1.0,\n","    top_k=0,\n","    top_p=0.9,\n","    repetition_penalty=1.0,\n","    num_return_sequences = num_sequences\n",")\n","\n","generated_sequences"]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["this royal throne of kings, this sceptred isle. \n"," with his gaze fixed on the marquise's fearful features, domen's plan finally yielded. though his foot might once again have steeled him, his resolve did not dare work. he continued\n","--------------------------------------------------------------------------------\n","this royal throne of kings, this sceptred isle would turn into a hostile world, and as our wretched ship walked the shores, wretched alliances would begin. in this way it was known that another land would soon be lost, the twin cities of the\n","--------------------------------------------------------------------------------\n","this royal throne of kings, this sceptred isle. if you are a part of my court and not my friends, then consider your words.'\n","'i have no interest in governing a kingdom that craves nothing but to rule,'he\n","--------------------------------------------------------------------------------\n","this royal throne of kings, this sceptred isle, is the fifth king of mallorea, this ship is the best captain in the fleet, and this ship is undefended except by a man - of - war, a mallorean sorcerer, a powerful\n","--------------------------------------------------------------------------------\n","this royal throne of kings, this sceptred isle, will be yours. you 'll be the wife of a king. you 'll wear my crown and be my wife.'\n"," the king looked down at his brother. \n","'you're a heartless\n","--------------------------------------------------------------------------------\n"]}],"source":["for sequence in generated_sequences:\n","    text = tokenizer.decode(sequence, clean_up_tokenization_spaces=True)\n","    print(text)\n","    print(\"-\" * 80)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.5"}},"nbformat":4,"nbformat_minor":0}
